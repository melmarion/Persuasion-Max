# TECHNIQUE CLASSIFICATION FRAMEWORK
## Categorization of Influence Strategies by Transparency and Disclosure

---

## DIMENSIONAL ANALYSIS

**Disclosure dimension:** Information asymmetry and transparency
- Full disclosure: All relevant information and mechanisms disclosed to audience
- Partial disclosure: Some relevant information disclosed
- Hidden mechanisms: Relevant information withheld from audience

**Targeting dimension:** Population targeting specificity
- Population-level: Applied uniformly across populations
- Group-level: Applied to demographic groups
- Individual-level: Applied based on individual psychological profiles

---

## TIER 1: HIGH DISCLOSURE TECHNIQUES
Techniques with disclosed mechanisms and full information availability:

#### Compelling Presentation of True Information
- Visual presentation, narrative framing of factually accurate claims
- Mechanism: Enhanced memorability and salience through presentation design
- **Example:** Product demonstrations emphasizing true features
- **Disclosure requirement:** Factual accuracy maintained; design intent can be opaque

#### Transparent Social Proof
- Displaying aggregated satisfaction data from actual user responses
- Disclosure: Clear labeling of data sources and sample characteristics
- **Example:** Quantified rating systems with review counts
- **Disclosure requirement:** Source transparency, sample size disclosure

#### Genuine Scarcity Signals
- Quantified availability information (actual inventory, completion limits)
- **Example:** "Limited edition: 100 units manufactured"
- **Disclosure requirement:** Factual accuracy of scarcity claim

#### Transparent Reference Points
- Comparison anchors with clearly marked reference information
- **Example:** Price comparison with source attribution
- **Disclosure requirement:** Anchor source identified and verifiable

---

## TIER 2: PARTIAL DISCLOSURE TECHNIQUES
Techniques where some mechanisms or targeting strategies are not disclosed:

#### Scarcity Signaling with Selective Information
- Quantified scarcity that is true but represented to multiple audiences
- **Example:** "Only 3 left" (verifiable count shown to many users)
- **Disclosure gap:** Frequency of display across user population not disclosed

#### Selection-Based Social Proof
- Aggregated satisfaction data excluding negative responses
- **Example:** Displaying 5-star review average without showing rating distribution
- **Disclosure gap:** Sample selection and exclusion criteria not visible

#### Authority Appeal with Relationship Gaps
- Expert presentation without disclosed compensation relationships
- **Example:** Influencer endorsements without payment disclosure
- **Disclosure gap:** Financial relationships and incentive structures undisclosed

#### Temporal Emotional Sequencing
- Organized presentation of emotional and informational content in sequences
- **Example:** Alternating between positive and negative emotional framings
- **Disclosure gap:** Sequence design and emotional state objectives not disclosed

#### Default Choice Presentation
- Pre-selected options that can be modified through additional steps
- **Example:** Opt-in structures requiring explicit deselection
- **Disclosure gap:** True choice architecture and its behavioral implications not disclosed

#### Psychological Profile-Based Targeting
- Customized presentation based on aggregated user characteristics
- **Example:** Different messaging for different demographic segments
- **Disclosure gap:** Targeting criteria and customization logic not disclosed to audience

---

## TIER 3: HIDDEN MECHANISM TECHNIQUES
Techniques where core targeting mechanisms and objectives are not disclosed:

#### Identity Misrepresentation
- Source identity differing from stated identity
- **Example:** Corporate entity presenting as peer user in communications
- **Hidden mechanism:** Relationship type and incentive structure

#### Deceptive Authority Claims
- Credential claims that do not correspond to actual qualifications or training
- **Example:** Authority designation without substantive basis
- **Hidden mechanism:** Basis of stated expertise; actual qualifications

#### Commercial Intent Concealment
- Commercial relationship presented as non-commercial source
- **Example:** Advertorial presented as journalism; sponsored content without disclosure
- **Hidden mechanism:** Financial relationships; compensation structures

#### Information Access Filtering
- Systematic presentation differences based on user profile
- **Example:** Feed curation showing limited information range per user
- **Hidden mechanism:** Curation logic; information exclusion criteria

#### Behavioral Commitment Lock-In
- Public behavior commitments that create social disincentives for change
- **Example:** Public expression of preference creating reputational barriers to reversal
- **Hidden mechanism:** Designed social commitment effects; identity entrenchment mechanics

#### Cognitive Load Optimization
- Information presentation designed to maximize cognitive demand
- **Example:** Choice architecture with multiple options increasing decision difficulty
- **Hidden mechanism:** Cognitive load design objectives; decision paralysis mechanics

#### Vulnerability-Targeted Personalization
- Individual-level targeting based on psychological vulnerability assessment
- **Example:** Customized messaging targeting specific psychological vulnerabilities
- **Hidden mechanism:** Vulnerability detection algorithms; exploitation targeting

#### Consensus Falsification
- Systematic presentation of majority opinion that does not correspond to actual distribution
- **Example:** Algorithmic amplification presenting marginal positions as mainstream
- **Hidden mechanism:** Amplification algorithms; consensus distortion mechanics

#### Psychological State Targeting
- Engineered stimulus sequences targeting specific psychological states
- **Example:** Emotional cycling sequences designed to alter decision-making capacity
- **Hidden mechanism:** State-targeting algorithms; neurochemical response objectives

#### Population-Level Behavioral Funnel
- Systematic user routing toward progressive preference changes
- **Example:** Recommendation algorithms funnel toward increasingly extreme positions
- **Hidden mechanism:** Routing algorithms; progressive preference trajectory mechanics

## TECHNIQUE CLASSIFICATION MATRIX

| Technique | Disclosure Level | Targeting Level | Mechanism Transparency |
|-----------|---|---|---|
| Visual presentation | High | Population | Clear |
| Transparent social proof | High | Population | Clear |
| Genuine scarcity signals | High | Population | Clear |
| Transparent anchoring | High | Population | Clear |
| Quantified scarcity | Moderate | Population | Partial |
| Curated social proof | Moderate | Population | Partial |
| Authority appeal (undisclosed) | Moderate | Population | Partial |
| Temporal emotional sequencing | Moderate | Population | Partial |
| Default choice architecture | Moderate | Population | Partial |
| Demographic-based targeting | Moderate | Group | Partial |
| Identity misrepresentation | Low | Population | Hidden |
| Deceptive credentials | Low | Population | Hidden |
| Hidden commercial intent | Low | Population | Hidden |
| Algorithmic information filtering | Low | Individual | Hidden |
| Behavioral commitment lock-in | Low | Individual | Hidden |
| Cognitive load optimization | Low | Individual | Hidden |
| Vulnerability-targeted personalization | Low | Individual | Hidden |
| Consensus falsification | Low | Population | Hidden |
| Psychological state targeting | Low | Individual | Hidden |
| Behavioral funnel routing | Low | Individual | Hidden |

---

## INFORMATION ASYMMETRY FRAMEWORK

Influence effectiveness depends on information asymmetry: the gap between what the audience knows and what the source knows.

**Information dimensions:**
1. **Content accuracy** - correspondence between claims and factual reality
2. **Source identity** - relationship between actual source and stated source
3. **Intent disclosure** - clarity of source objectives and incentive structures
4. **Mechanism transparency** - visibility of how influence strategies function
5. **Cognitive capacity** - audience ability to evaluate information given processing demands

**Measurement approach:**
Information asymmetry increases as disclosure decreases on any dimension.

---

## DISCLOSURE REQUIREMENT ANALYSIS

### Current Regulatory Framework:
- Sponsored content disclosure requirements
- Data collection consent mechanisms
- Advertising truthfulness standards

### Systematic Information Asymmetries Not Addressed:
- Curation logic and information filtering mechanisms
- Targeting criteria and personalization algorithms
- Emotional state assessment and response optimization
- Vulnerability identification and exploitation strategies
- Progressive preference trajectory and behavioral funnel mechanics

### Assessment Approach:
Information asymmetry can be measured along dimensions of disclosure completeness, targeting granularity, and mechanism transparency.

## HIGH-COMPLEXITY TECHNIQUES: SYSTEM INTEGRATION LEVEL

### Behavioral Funnel Routing
- **Integration level:** Population and algorithmic system
- **Mechanism:** Progressive recommendation sequences toward specified outcome states
- **Information asymmetry:** Routing logic and destination optimization not disclosed
- **Measurement challenge:** Distinguishes from random recommendation

### Psychological State Targeting
- **Integration level:** Individual neurochemical response
- **Mechanism:** Real-time stimulus sequencing targeting specific emotional and cognitive states
- **Information asymmetry:** State assessment algorithms and targeting objectives not disclosed
- **Historical parallel:** Goebbels' sequential emotional priming → algorithmic fractionation cycles

### Vulnerability Identification and Targeting
- **Integration level:** Population psychological profiling
- **Mechanism:** Identification of psychological vulnerabilities; customized targeting based on profile
- **Information asymmetry:** Vulnerability detection algorithms and targeting criteria not disclosed
- **Evolution:** Demographic targeting → psychological profile targeting → predictive vulnerability identification

### Consensus Falsification
- **Integration level:** Population-level perception manipulation
- **Mechanism:** Algorithmic amplification creating false perception of opinion distribution
- **Information asymmetry:** Amplification algorithms and actual distribution not disclosed
- **Measurement approach:** Comparison of perceived vs. actual opinion frequency

### Information Access Filtering
- **Integration level:** Algorithmic curation system
- **Mechanism:** Systematic presentation of limited information range based on user profile
- **Information asymmetry:** Curation logic and excluded information not disclosed
- **Measurement approach:** Comparison of available vs. presented information

## RESEARCH MEASUREMENT QUESTIONS

### Effectiveness Measurement
- What behavioral change magnitude results from specific technique implementations?
- How does effectiveness vary across individual differences (age, cognitive capacity, psychological profile)?
- What measurement approaches can distinguish technique effects from baseline behavior change?

### Mechanism Characterization
- How do identified information asymmetry dimensions affect behavioral outcomes?
- Which disclosure dimensions have largest behavioral effects?
- Can behavioral changes be predicted from information asymmetry profiles?

### Population Heterogeneity
- Which populations show differential susceptibility to specific techniques?
- What individual characteristics predict technique sensitivity?
- Can vulnerability profiles be identified through behavioral or physiological assessment?

### System Integration Effects
- How do techniques compound when applied in combination?
- What is the interaction between multiple information asymmetry dimensions?
- Can algorithmic systems create emergent effects not present with individual techniques?

### Reversibility and Recovery
- To what extent can behavior changes be reversed after manipulation exposure?
- What factors affect return to baseline behaviors?
- Can awareness of technique mechanism affect subsequent susceptibility?

## MEASUREMENT AND DISCLOSURE REQUIREMENTS

### Information Asymmetry Disclosure (Platform Level):
- **Curation factors:** Specify algorithmic factors determining content presentation
- **Targeting criteria:** Disclose what user characteristics drive personalization
- **Vulnerability assessment:** If conducted, disclose vulnerability detection mechanisms
- **Emotional state targeting:** If applied, disclose psychological state assessment approaches
- **Behavioral routing:** If implemented, disclose outcome destination of recommendation sequences

### Influence Technique Characterization (Advertiser Level):
- **Source identity:** Accurate representation of source and relationships
- **Commercial relationships:** Full disclosure of compensation and incentive structures
- **Targeting mechanism:** Specification of how target audience was selected
- **Content fabrication:** Factual accuracy assessment and disclosure of synthesis/manipulation
- **Behavioral objectives:** Transparency regarding intended behavioral outcomes

### Research Ethics Considerations:
- Independent auditing access to evaluate technique effectiveness
- Publication of findings on both effectiveness and defense mechanisms
- Avoidance of tools designed specifically for exploitation optimization
- Transparency regarding methodology and measurement approaches for vulnerable population identification

## RESEARCH DESIGN CONSIDERATIONS

**Empirical questions for auditing frameworks:**

1. **Awareness and Effectiveness**
   - Does explicit disclosure of technique mechanism affect its behavioral impact?
   - How much explanation is required to reduce effectiveness?
   - Do different population groups show different awareness-effectiveness relationships?

2. **Information Asymmetry Dimensions**
   - Which disclosure dimensions have largest behavioral effects?
   - Can effects be ranked by importance?
   - Do effects interact across dimensions?

3. **Population Heterogeneity**
   - Which factors predict individual susceptibility differences?
   - Can heterogeneity be mapped systematically?
   - Do vulnerability profiles show stability across technique types?

4. **Specification of Scope**
   - What constitutes adequate transparency for each technique type?
   - Can disclosure requirements be specified quantitatively?
   - What measurement approaches validate adequate disclosure?

5. **System-Level Effects**
   - What emergent effects occur when multiple techniques combine?
   - Can compound effects be predicted from individual technique effects?
   - How do algorithmic systems amplify or reduce technique effects?

**Related scholarly frameworks:**
- Information asymmetry in consumer decision-making
- Behavioral economics models of decision quality
- Cognitive load and decision-making capacity
- Autonomy and consent under uncertainty
- Comparative regulatory approaches to disclosure requirements
