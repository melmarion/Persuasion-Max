# Ethical Framework: Boundaries and Audit Standards
## Moral Guidelines for Influence Technique Classification

---

## PURPOSE

This document defines ethical boundaries for influence techniques. It provides:
1. Three bright-line rules (what is prohibited)
2. Classification tiers by disclosure level
3. Audit checklists for compliance
4. Disclosure requirements

**Note:** For effectiveness metrics and detection methods, see `DETECTION/12_PSYCHOLOGICAL_PRINCIPLES_DETECTION_FRAMEWORK.md` and `DETECTION/17_MACHINE_READABLE_DETECTION_SYSTEM.md`.

---

## THE THREE BRIGHT LINES

### üî¥ RULE 1: NO FALSE CLAIMS ABOUT PRODUCT FUNCTION

**Violations Include:**
- **Fake Authority/Credentials:** Deepfakes, fabricated experts, AI-generated credentials
- **Deceptive Identity:** Corporate posing as peer user, paid posters as organic users, astroturfing
- **Hidden Commercial Intent:** Advertorial as journalism, undisclosed sponsored content
- **Systematic Isolation:** Algorithmic bubble removing counter-narratives completely
- **Cognitive Overload:** Information overwhelm designed to disable conscious decision-making
- **False Consensus:** Bot armies, coordinated inauthentic behavior, algorithmic amplification creating fake majority perception

---

### üü† RULE 2: NO OBSTRUCTION OF EXIT

**Violations Include:**
- **Dark Patterns:** Hidden cancellation, more steps to cancel than signup, repeated opt-out confirmations
- **Delayed Deletion:** 30-day account deletion with re-activation offers, data persisting after deletion request
- **Hidden Opt-Out:** Buried unsubscribe links, requiring login to unsubscribe from email

---

### üü° RULE 3: NO TARGETING CRISIS STATES

**Violations Include:**
- **Predatory Targeting:** Children with addictive content, addiction history targeting, payday loans to trapped demographics
- **Identity Lock-In Exploitation:** Making belief change require public humiliation, tribal belonging as hostage
- **Radicalization Engineering:** Deliberately pushing toward extremism, funneling vulnerable individuals to extreme content
- **Emotional State Exploitation:** Engineered emotional cycles reducing critical thinking when targeting vulnerable populations

---

## TECHNIQUE CLASSIFICATION BY DISCLOSURE

### Tier 1: Full Disclosure (Ethical)
- All relevant information and mechanisms disclosed to audience
- Factual accuracy maintained
- Design intent transparent
- **Examples:** Product demonstrations with true features, transparent social proof with source data, genuine scarcity signals

### Tier 2: Partial Disclosure (Gray Zone)
- Some relevant information disclosed
- Mechanisms or targeting strategies not fully visible
- Legal but ethically questionable
- **Examples:** Curated reviews (showing best, hiding worst), undisclosed influencer compensation, default choice architecture

### Tier 3: Hidden Mechanisms (Prohibited)
- Relevant information withheld from audience
- Core targeting mechanisms and objectives concealed
- Violates one or more bright lines
- **Examples:** Identity misrepresentation, deceptive credentials, algorithmic isolation without counter-narrative access

---

## TARGETING DIMENSION ETHICS

| Targeting Level | Ethical Status | Condition |
|-----------------|----------------|-----------|
| **Population-Level** | ‚úÖ Generally OK | Standard service delivery |
| **Group-Level** | üü° Requires disclosure | Demographic targeting with transparency |
| **Individual-Level** | üü°/üî¥ Depends | OK if not targeting vulnerabilities; prohibited if exploiting crisis states |

---

## ETHICAL BOUNDARIES BY TECHNIQUE

| Technique | Ethical When | Prohibited When |
|-----------|--------------|-----------------|
| **Authority signals** | Real credentials, disclosed relationships | Fake credentials, deepfakes |
| **Social proof** | Real testimonials, shown distribution | Fake reviews, bot armies, deceptive selection |
| **Scarcity signals** | Honest availability | Fake scarcity ("Only 3 left" that refreshes) |
| **Anchoring** | Transparent reference point | Fake original prices |
| **Reciprocity** | Transparent exchange | Hidden quid pro quo |
| **Default architecture** | Transparent, easily reversible | Hidden, difficult to change |
| **Commitment** | Voluntary | Coerced public commitment |
| **Personalization** | Efficient matching | Targeting vulnerable populations |
| **Repetition** | Transparent | Deceptive (pretending to be random) |
| **Framing** | True facts, alternative angle | Facts selected to misrepresent |
| **Tribe/community** | Genuine shared interests | Algorithmic tribalization with artificial enemies |
| **Emotional content** | Authentic emotion | Engineered cycles targeting vulnerable users |

---

## AUDIT CHECKLISTS

### Rule 1 Audit (False Claims)
- [ ] Can every product claim be verified?
- [ ] Are data practices accurately described?
- [ ] Are paid endorsements clearly disclosed?
- [ ] Are credentials real, not synthetic?
- [ ] Is all social proof genuine (with distribution shown)?
- [ ] Is source identity accurately represented?
- [ ] Are commercial relationships transparent?

### Rule 2 Audit (Obstruction of Exit)
- [ ] Is cancellation as easy as signup?
- [ ] Can users delete data immediately?
- [ ] Is opt-out one-click?
- [ ] Are there no repeated confirmation screens?
- [ ] Is account deletion permanent without mandatory waiting?
- [ ] Is unsubscribe link visible and functional?

### Rule 3 Audit (Crisis Targeting)
- [ ] Are minors protected from addictive design?
- [ ] Is radicalization content not algorithmically accelerated?
- [ ] Are vulnerable populations not micro-targeted?
- [ ] Is urgency language not used on crisis-state users?
- [ ] Is the business model not dependent on exploitation?
- [ ] Are addiction-prone users not specifically targeted?

**If you answer "No" to any question: Fix it before launch.**

---

## DISCLOSURE REQUIREMENTS

### Platform-Level Disclosure
- **Curation factors:** Specify algorithmic factors determining content presentation
- **Targeting criteria:** Disclose what user characteristics drive personalization
- **Vulnerability assessment:** If conducted, disclose vulnerability detection mechanisms
- **Emotional state targeting:** If applied, disclose psychological state assessment approaches
- **Behavioral routing:** If implemented, disclose outcome destination of recommendation sequences

### Advertiser-Level Disclosure
- **Source identity:** Accurate representation of source and relationships
- **Commercial relationships:** Full disclosure of compensation and incentive structures
- **Targeting mechanism:** Specification of how target audience was selected
- **Content fabrication:** Factual accuracy assessment and disclosure of synthesis/manipulation
- **Behavioral objectives:** Transparency regarding intended behavioral outcomes

---

## INFORMATION ASYMMETRY FRAMEWORK

Ethical evaluation depends on information asymmetry: the gap between what the audience knows and what the source knows.

**Five Information Dimensions:**
1. **Content accuracy** - Correspondence between claims and factual reality
2. **Source identity** - Relationship between actual source and stated source
3. **Intent disclosure** - Clarity of source objectives and incentive structures
4. **Mechanism transparency** - Visibility of how influence strategies function
5. **Cognitive capacity** - Audience ability to evaluate information given processing demands

**Ethical Principle:** As information asymmetry increases (less disclosure), ethical risk increases.

---

## WHAT'S PERMITTED VS. PROHIBITED

### ‚úÖ PERMITTED (Within Ethical Bounds)
- Use psychological principles with transparency
- Optimize for engagement with disclosed mechanisms
- Personalize content without targeting vulnerabilities
- Create tribal belonging with genuine shared interests
- Use emotional content authentically
- Engineer choice architecture that's easily reversible
- Deploy authority figures with real credentials
- Show social proof with accurate distribution

### ‚ùå PROHIBITED (Crosses Bright Lines)
- Make false claims about function/outcomes
- Hide commercial intent or paid relationships
- Obstruct user exit or data deletion
- Target people identified as in crisis states
- Use deepfakes or fabricated credentials
- Create algorithmic monopolies on truth (no counter-narrative access)
- Disable conscious decision-making through overload
- Force behavioral commitment without consent
- Engineer radicalization pathways

---

## REGULATORY GAPS

Current regulations address:
- Sponsored content disclosure requirements
- Data collection consent mechanisms
- Advertising truthfulness standards

**Not Currently Regulated (But Ethically Problematic):**
- Curation logic and information filtering mechanisms
- Targeting criteria and personalization algorithms
- Emotional state assessment and response optimization
- Vulnerability identification and exploitation strategies
- Progressive preference trajectory and behavioral funnel mechanics

---

## RESEARCH ETHICS

When studying influence techniques:
- Independent auditing access to evaluate technique effectiveness
- Publication of findings on both effectiveness AND defense mechanisms
- Avoid creating tools designed specifically for exploitation optimization
- Transparency regarding methodology for vulnerable population identification
- Framing: understanding for protection, not offense

---

## REFERENCES

**Foundational:**
- Cialdini, R. "Influence: The Psychology of Persuasion"
- Sunstein, C. "Nudge"
- Kahneman, D. "Thinking, Fast and Slow"

**Modern:**
- Zuboff, S. "The Age of Surveillance Capitalism"
- Noble, S. "Algorithms of Oppression"

**Historical:**
- Arendt, H. "Origins of Totalitarianism"

---

**Operating Principle:** Everything above the three bright lines is permitted. Everything below them is prohibited.
